# config.yaml
query: Simulate a liquidity crisis in a Core-Periphery banking network. Banks exist in three states-> 'Solvent', 'Distressed' ( spreading financial stress to neighbors), and 'Liquidated' (removed from the system). Distressed banks transmit stress to Solvent neighbors with a probabilistic transmission rate $\beta$, and are eventually liquidated at rate $\gamma$. Compare the peak number of Distressed banks (peak prevalence) when the crisis starts in a highly connected Core node versus a generic Periphery node. Does the Core-seeded crisis reach its peak faster?Address this question in both scenarios in analytcal and simulation approaches. User is not available to provide more information.
name: "quesiton9"
workflow:
  copilot: False # whether to use copilot mode or not
  scientist_modules: # which modules to use in the scientist workflow, for reasoning models like openai's o3, planing might not be necessary
    plan: True
    reflect: True 
  reflection_max_iters: 1 # how many times the scientist can reflect (the higher is not necessarily better, start from lower values and increase if needed)
  no_retries: 50 # no  of scientist retries till generate the structured output
  no_paper_revise: 0 # no of times the scientist can revise the paper, best to test it with 0, if needed increase it to higher values

llm:
  scientists:
    provider: openai          # one of: openai, grok
    model: gpt-4.1   # model name

  experts:
    provider: openai
    model: gpt-4.1-mini

  mathematician_expert:
    provider: openai
    model: o3-mini

  vision_expert:            # make sure the model supports vision inputs!!!
    provider: openai
    model: gpt-4.1-mini

paths:
  output_dir: user-files
  contact_network_path: "none"
  data_path: "none"
