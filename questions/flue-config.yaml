# config.yaml
query: I am providing time-series data from the famous 1978 English Boarding School Influenza A/H1N1 outbreak. This dataset is known as an \"epidemic enigma\" because standard SEIR models often fail to fit the data while correctly predicting the final Attack Rate (AR).Parameters & Constraints:Total Population ($N$): 763 students\n.Observed Attack Rate-> 512 students (67%) were eventually infected.\nData Interpretation-> The data columns in the Excel file  represent time,  \"Confined to Bed\" ($B$) and \"Convalescent\" ($C$) numbers.Crucial Note-> Do not treat \"Confined to Bed\" ($B$) as the primary \"Infectious\" ($I$) stage. The paper suggests an unobserved highly infectious stage ($I$) precedes the \"Confined to Bed\" stage ($B$). $B$ acts effectively as a quarantine state where infectivity drops or stops.Virus Characteristics-> Influenza A/H1N1. The generation time is likely short (approx. 1.9 days), and the Basic Reproduction Number ($R_0$) is estimated to be high (possibly > 8) due to the closed environment\n.Your Task:Analyze the provided output/cases_data.xlsx to extract the daily prevalence of students confined to bed and convalescing.Fit a compartmental model (or agent-based equivalent) to this data. You must prioritize matching two objectives simultaneously:The shape of the \"Confined to Bed\" curve.The total Attack Rate of ~512 students (standard models often overshoot to 100% infection or fail to match the curve)\nOutput-> Report the $R_0$ your model estimated, the calculated Attack Rate, and a comparison of your predicted peak vs. the data's peak
name: "flue-1978"
workflow:
  copilot: False # whether to use copilot mode or not
  scientist_modules: # which modules to use in the scientist workflow, for reasoning models like openai's o3, planing might not be necessary
    plan: True
    reflect: True 
  reflection_max_iters: 1 # how many times the scientist can reflect (the higher is not necessarily better, start from lower values and increase if needed)
  no_retries: 5 # no  of scientist retries till generate the structured output
  no_paper_revise: 0 # no of times the scientist can revise the paper, best to test it with 0, if needed increase it to higher values
  time_out_tools: 600  # default timeout for tool execution in seconds
llm:
  scientists:
    provider: openai          # one of: openai, grok
    model: gpt-4.1   # model name

  experts:
    provider: openai
    model: gpt-4.1-mini

  mathematician_expert:
    provider: openai
    model: o3-mini

  vision_expert:            # make sure the model supports vision inputs!!!
    provider: openai
    model: gpt-4.1-mini

paths:
  output_dir: "user-files"
  contact_network_path: "NONE"
  data_path: "questions/cases_data.xlsx"
